# VAMSI KRISHNA YARRAGUNTA(700772692)  
This project implements Linear Regression from scratch using both the Normal Equation and Gradient Descent. The goal is to compare both methods on synthetic data generated from the equation ğ‘¦ = 3 + 4 ğ‘¥ + ğœ– y=3+4x+Ïµ.  
**â€¢	A short explanation of the results.**  
Both the closed-form solution (Normal Equation) and Gradient Descent converge to nearly the same parameters (intercept â‰ˆ 3, slope â‰ˆ 4), which matches the true underlying model. The loss curve confirms that gradient descent reduces error over time until it stabilizes. This demonstrates that Gradient Descent is an effective optimization method for linear regression, especially useful when closed-form solutions are computationally expensive for large datasets.
